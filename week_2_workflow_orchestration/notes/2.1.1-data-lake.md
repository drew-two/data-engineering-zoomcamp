# 2.1.1 - Data Lakes

Agenda
* What is a Data Lake
* Data Lake vs Data Warehouse
* Gotchas of Data Lakes
* ELT vs. ETL
* Cloud provided Data Lake

## Data Lakes

![Data Lake](week_2_workflow_orchestration/images/2.1.1-data-lake.PNG)
- Central repository which holds big data from many sources
- Can be unstructured, semistructured or structured
- Idea is to ingest data and make accessible to the team as quickly as possible
- Used extensively for machine learning and analytical solutions
- Usually make some form of metadata for faster access
- Needs to be **secure**, and should scale
- Hardware should be inexpensive, to import as much data as quickly as possible

## Data Lake vs Data Warehouse
- Data Lakes are for data scientists or dat analysts
    - Raw - generally unstructured or semistructed with minimal processing
    - Large - on the order of petabytes
    - Undefined - Can be used for many applications
        - Stream processing
        - Machine Learning
        - Realtime analytics
- Data warehouses are for business analysts
    - Refined - highly structured, cleaned, pre-processed and refined (specific use cases)
    - Smaller - less, in the order of terabytes; pre-processed and purged regularly
    - Relgational - historic/relational data
        - Transactional systemms
        - Operational data

## How did it start?
Why did Data Lakes take off when companies were happy with Data Warehouses?
- Companies realized the value of data
    - Companies developed projects/products totally revolving around data and made huge revenue
- Store and access data quickly
    - Did not want to wait for a team to develop structure/relations before it can be used
- Cannot always define structure of data
- Usefulness of data being realized later in project lifecycle
- Increase in data scientists
- R&D on data products
- Need for cheap storage of big data

## ETL vs ELT
- Export, Transport and Load vs Export, Load and Transform
- ETL mainly for small amounts of data vs ELT mainly used for large amounts of data
- ELT provides data lake support (Schema on read)
    - Write data first, determine schema on read 
    - ETL mainly for data warehousing (Schema on write)

## Gotchas of Data Lake
Often becomes "Data Swamp" over time
- No versioning
- Incompatible schemas for same data without versioning
    - Often write data in avro, then next day write parque in the same directory as parquet
    - Can become useless for users
- No metadata associated - hard to determine usefulness of data
- Joins not possible (different datasets)
    - E.g. no foreign key applicable

## Cloud Providers
- GCP - cloud storage
- AWS - S3
- Azure - Azure Blob