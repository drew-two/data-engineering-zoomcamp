# 1.2.1 - Introduction to Docker

Docker is a OS-level virtualization tool that delivers tools called 'containers'
- Isolated from one another and bundle their own software, librarie and configuration
- Can communicate through well-defined channels

Download Docker for Windows [here](https://www.docker.com/products/docker-desktop/)
- Or install docker.io in your package manager

Using Docker we can run many pipelines in separate containers
- E.g. One container runs Ubuntu 20.04
    - Uses Python 3.9, Pandas, Postgres connection library
- E.g. Postgres container (Without installing anything)
    - We can run one on our host computer as well, and they will not conflict
- E.g. PGAdmin (without installing anything)
    - Can use this for Postgres GUI

Docker also gives software reproducibility
- Image is like a snapshot of environment with OS and data/code
- We can take image and upload to GCP
    - Resulting environment will be identical to one on computer

## Pipelines

Data pipelines is a name for a service that processes data and outputs some data
- Could be:
    - **Input data (E.g. CSV) -> Data Pipeline (Python script) -> Output Data (E.g. SQL table)**
- Pipeline could run arbitrary steps, including other data pipelines
- Pipelines can be an arbitrary amount of steps and databases

## Why Should We Care About Docker?

- Reproducibility
- Local experimentations
- Integration tests (CI/CD)
    - Can apply tests on data pipelines in Docker environments
- Running pipelines on the cloud (AWS Batch, Kubernetes jobs)
- Spark
    - Library to specify data pipelines
- Serverless (AWS Lambda)
    - Good to do data pipelines one at a time

## Demo

Open terminal window (can use MINGW, WSL), open or create [../2_docker_sql/Dockerfile](../2_docker_sql/Dockerfile)
- Try runnning `docker run hello-world`
    - Custom docker image used just to check Docker is working
- Running Ubuntu via `docker run -it ubuntu bash`
    - Ubuntu is the image to run, bash is the command (opens terminal in the container)
    - Use container bash prompt, try running `rm -rf ./*`
        - This removes every command as there are no more files
- Run ubuntu again
    - Notice that everything is back
    - The point is that when something happens in the container, host machine is not affected (except for mounts)
- Try running `docker run -it python:3.9`
    - The 3.9 is a version tag, this version of the python image runs Python 3.9
    - Opens Python terminal interactively
    - Say we want to run Pandas. Not installed and we cannot install via pip in this container
    - Instead, run `docker run -it --entrypoint=bash python:3.9`
        - This opens bash instead of Python, can run `pip install pandas` now
        - Type `python` to open the Python prompt again and use pandas
- If run `docker run -it python:3.9` again, pandas will be gone
    - Images for containers are specified at a state/certain point in time
    - The image python:3.9 does not have pandas
- How do we add this? With a **[Dockerfile](../2_docker_sql/Dockerfile)**.

## Dockerfile

This specifies a Docker image and what we want it to start with
```
FROM python:3.9

RUN pip install pandas

ENTRYPOINT ['bash']
```
- This Dockerfile changes some things
    - Besides adding the pandas library, we change the entrypoint to `bash` from Python.
- Build and run this image:
    - Run with `docker build -t test:pandas .`
        - Need to specify `-t` to tag the image, we chose test with version pandas
        - `.` is used to specify where Dockerfile is
    - Can see Docker image being built, installing pandas via pip etc
- Run with `docker run -it test:pandas`, Python will now have pandas

## Make Pipeline

Create or look at [`pipeline.py`](../2_docker_sql/pipeline.py)
- Add dummy code:
    ```
    print(f'job finished successfully')
    ```
- Add the following to the Dockerfile:
    ```
    FROM python:3.9

    RUN pip install pandas

    WORKDIR /app
    COPY pipeline.py pipeline.py

    ENTRYPOINT ['bash']
    ```
    - Uses `/app` to put working files, and puts the pipeline script in there
- Build it, can use the same tag
    - Faster, as the old image layers were cached
- Run it with `docker run -t test:pandas`
    - Current directory is now `/app` with the script
    - Run the pipeline with `python pipeline.py`
- To call this container a pipeline, it needs to be fully automated (can't run pipeline.py)
    - May also want to add parameters, specify time of day of job etc

- Adjust [`pipeline.py`](../2_docker_sql/pipeline.py):
    ```
    import sys

    import pandas as pd

    print(sys.argv)

    day = sys.argv[1]

    # some fancy stuff with pandas

    print(f'job finished successfully for day = {day}')
    ```
    - Here we add the day of week as a command line argument
- Adjust [Dockerfile](../2_docker_sql/Dockerfile) entrypoint to run pipeline:
    ```
    FROM python:3.9

    RUN pip install pandas

    WORKDIR /app
    COPY pipeline.py pipeline.py

    ENTRYPOINT ['python', 'pipeline.py']
    ```
- Add parameter to container run by running `docker run -it test:pandas 2021-01-15`
    - The last token is the command line parameter
    - We see the python script got the date and printed the date properly
    - If we add more command line arguemnts, we can see the rest will be found by Python